<?xml version="1.0" encoding="ISO-8859-1" ?>
<fml-apml id="$fml_id$">
	<bml>
		<speech id="s1" start="0.0" language="english" voice="openmary" type="SAPI4" text="">
			<description level="1" type="gretabml">
				<reference>tmp/from-fml-apml.pho</reference>
			</description>
				
			<tm id="tm1"/>
				When an agent is controlled by the Greta Platform, like me, 
				conversational moves are specified using FML for Greta agents,  
			<tm id="tm2"/>
				containing text and an abstract representation of intentions.
			<tm id="tm3"/>	
				The Greta platform enriches this with 
			<tm id="tm4"/>
				automatic non-verbal behaviour.
			<tm id="tm5"/>	
			
			<pitchaccent id="pa1" type="HStar" level="medium" start="s1:tm1+0.5" end="s1:tm2" importance="1"/>
			<pitchaccent id="pa2" type="HStar" level="medium" start="s1:tm2+0.2" end="s1:tm3" importance="1"/>
			<pitchaccent id="pa3" type="HStar" level="medium" start="s1:tm4" end="s1:tm5" importance="1"/>
			<boundary type="LH" id="b1" start="s1:tm2" end="s1:tm2+0.5"/>
			<boundary type="LL" id="b2" start="s1:tm3" end="s1:tm3+0.5"/>
			<boundary type="LL" id="b3" start="s1:tm5" end="s1:tm5+0.5"/>
		</speech>
	</bml>
	<fml>
		<rest id="r1" type="restposealong_big" start="s1:tm1" end="s1:tm2" importance="1.0"/>
		<emotion id="e1" type="joyStrong" start="s1:tm1" end="s1:tm2" importance="1.0"/>	
		<emotion id="e1" type="joyStrong" start="s1:tm3" end="s1:tm4" importance="1.0"/>	
		<deictic id="d1" start="s1:tm1" end="s1:tm1+1" importance="1.0" target="head_COUCH_USER_OLD"/>
		<deictic id="d2" start="s1:tm2" end="s1:tm2+1" importance="1.0" target="head_COUCH_M_2_OLD"/>
		<deictic id="d3" start="s1:tm3" end="s1:tm3+1" importance="1.0" target="head_COUCH_USER_OLD"/>
			
	</fml>
</fml-apml>
