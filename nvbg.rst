Non Verbal Behavior Generator 
=====

NVBG (Non Verbal Behavior Generator) has been merged to GRETA to allow the latter to perform gestures computed by NVBG. NVBG work with a software named SmartBody to perform the gesture that it has found.

Plenty of these gesture have been created also in GRETA to perform a map from NVBG Gesture and the GRETA Gesture using a mapping file

NVBG Traitement is located in two different place:

* Planner
* BML File Reader

In this way, GRETA will use be able to add the gestures found thanks NVBG to those found by the lecture of the FML or the BML.
NVBG will generate a new BML file for the FML and BML with only the gesture found by itself in this way it's easy to look at  what it has done.

NVBG needs only to know the Speech to perform its treatement. The Speech is available as a SpeechSignal  and it can be found in the list of Signals which is in both  Planner and the BML File Reader. 

The Speech is extracted from the SpeechSignal and then is modified to be understandable by NVBG as a VrExpress Message.

vrExpress Message
-----

.. image:: https://github.com/isir/greta/blob/gpl-grimaldi/pictures/vrExpress.jpg

A vrExpress Message is the way that NVBG uses to communicate between its components. One doesn't need to specify the intentions (intention tags omitted), they will be computed automatically, instead it's mandatory to define a character that will take in charge the message process (harmony in the photo).

Two characters are generated by default by NVBG: Brad and Rachel 

Launch NVBG
-----

From the Planner or the BML File Reader , GRETA will launch NVBG and the Charniak Parser 

In the run-toolkit-all.bat is specified to launch NVBG with some arguments:

* Characters that will have to process the speech
* Rules-Input file for each character (it will define how the character will treat the speech)
* NVBG-Rules.xls: it will define the structure of the response 
* NVBG-Transform.xls: used by NVBG-Rules , define the structure of the response
* NVBG-BahviorDescription.xls: used by NVBG-Rules, define the structure of the response

.. image:: https://github.com/isir/greta/blob/gpl-grimaldi/pictures/NVBG_cap.jpg

The parser is launched just after the launch of NVBG, it will parse the speech and send it ,once parsed, back to NVBG.

Find NVBG Gesture and Conversion to GRETA Gesture
-----

From the Planner or the BML File Reader , GRETA will launch NVBG and the Charniak Parser and send to it the speech as vrExpress Message, then NVBG will send back the encrypted response  of the treatement that will contain some <animation> tags that will be decrypted.Those elements contain the gesture that NVBG found for SmartBody. 

We now need to convert the tags "animation" to the tag <gesture> which is understandable by GRETA , to add the type of the gesture (i.e beat etc..), to change the gesture name using the mapping file (i.e NVBGBeatLow->GRETABeatLow) 

The mapping file contains a the NVBG gestures, GRETA gestures and the type of the latter. Each line contains a NVBG Gesture and its version made in GRETA 
The type is stocked in another mapping file which will map the type of NVBG Gestures and GRETA Gesture.

The mapping file will contain the elements separated by **::** to make the file easy to parse. (i.e. **NVBGBeatLow::GRETABeatLow**), The same is done for the type.

At the last we need to delete from the line on the gesture some informations which are not useful (importance) and to add the start and end of the gesture.

At the end of the traitement we will have the line containing the gesture. We now need to add the "context" around the gesture, for that we recreate locally a BML using the speech and it will contain the gestures found by NVBG.

The last step is to use the convert the BML to Signals (GesturesSignals essentially) and to add these signals to the existing signals, then GRETA's BehaviorRealizer will process them.


